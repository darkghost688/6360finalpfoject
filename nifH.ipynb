{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose and significance\n",
    "\n",
    "## Background\n",
    "\n",
    "The nifH gene is an important marker gene for studying biological nitrogen fixation function. By analyzing the sequence characteristics of the gene (such as GC content, sequence length, etc.), its functional activity or abundance can be evaluated. This is of great significance for understanding the nitrogen cycle in marine ecosystems.\n",
    "\n",
    "## Research purpose\n",
    "\n",
    "1. Explore the relationship between the key characteristics and functional activity of the nifH gene.\n",
    "\n",
    "2. Use machine learning models (linear regression, random forest, neural network) to predict the nitrogen fixation function of unknown samples.\n",
    "\n",
    "3. Compare the performance of different models and evaluate their applicability in bioinformatics analysis.\n",
    "\n",
    "## Significance\n",
    "\n",
    "By introducing the model method, it is possible to:\n",
    "\n",
    "1. Improve the accuracy of nitrogen fixation gene function prediction and expand its application scenarios.\n",
    "\n",
    "2. Capture complex feature relationships and provide references for future gene function research.\n",
    "\n",
    "3. Build a general analysis framework to provide methodological support for other gene function analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID: Unique identifier of the gene sequence.\n",
    "\n",
    "## Sequence: The base sequence of the gene (A, T, C, G).\n",
    "\n",
    "## Length: The length of the gene in base pairs.\n",
    "\n",
    "## GC_Content: GC content, which is (G + C) / total length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score ,classification_report,ConfusionMatrixDisplay\n",
    "from collections import Counter\n",
    "from Bio import SeqIO\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 是一个典型的 nifH 基因序列长度范围，GC 含量为 0.646，符合固氮基因常见的高 GC 含量特性。 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the master data folder path\n",
    "# 定义主数据文件夹路径\n",
    "data_folder = \"./nifHdata\"\n",
    "\n",
    "# Stores a list of all sequences\n",
    "# 存储所有序列的列表\n",
    "all_sequences = []\n",
    "\n",
    "# Tags, tags for each genome\n",
    "# 标签，每个基因组的标签\n",
    "all_labels = []\n",
    "\n",
    "all_annotations = []  # 存储注释信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse 20 folders\n",
    "# 遍历20个文件夹\n",
    "for i in range(20):\n",
    "    folder_name = f\"nifH_datasets ({i})\" if i > 0 else \"nifH_datasets\"\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    gene_file = os.path.join(folder_path, \"ncbi_dataset/data/gene.fna\")\n",
    "    \n",
    "    # Make sure the file exists\n",
    "    # 确保文件存在\n",
    "    if os.path.exists(gene_file):\n",
    "        # Read sequence and annotation information from fasta files\n",
    "        # 读取 fasta 文件中的序列和注释信息\n",
    "        for record in SeqIO.parse(gene_file, \"fasta\"):\n",
    "            all_sequences.append(str(record.seq))  # 转换为字符串存储\n",
    "            all_annotations.append(record.description)  # 存储注释信息\n",
    "            all_labels.append(i)  # 标签对应文件夹编号\n",
    "    else:\n",
    "        print(f\"can not find file：{gene_file}\")\n",
    "\n",
    "\n",
    "# 打印结果\n",
    "print(f\"successfully load {len(all_sequences)} sequence！\")\n",
    "print(f\"total {len(set(all_labels))} categories, the labeled are{set(all_labels)}\")\n",
    "print(\"Example sequence:\", all_sequences[0][:50], \"...\")  # 只显示第一条序列前 50 个字符\n",
    "print(\"Example annotation:\", all_annotations[0])  # 显示第一条序列的注释信息\n",
    "print(\"Example tags:\", all_labels[0])  # 显示第一条序列的标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each sequence, one per line\n",
    "# 打印每条序列，每行一条\n",
    "for idx, sequence in enumerate(all_sequences):\n",
    "    print(f\"sample {idx + 1}:\\n{sequence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all sequences to a file\n",
    "# define the output file name\n",
    "output_file = \"sequences_output.dat\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for idx, sequence in enumerate(all_sequences):\n",
    "        f.write(f\"sample {idx + 1}:\\n{sequence}\\n\\n\")\n",
    "\n",
    "print(f\"all the sequence have saved into: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly convert these original sequences into One-hot encoding\n",
    "\n",
    "### The main reason for converting the original sequence into one-hot encoding is to represent the gene sequence in a numerical form that can be understood by computers while retaining biological information.\n",
    "\n",
    "The original gene sequence is composed of characters (such as A, T, G, C, etc.), which cannot be processed directly by computers. Before modeling, these characters need to be converted into numerical form, and One-hot encoding is a common representation method that can retain the information of each base in the original sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义 One-hot 编码函数\n",
    "def one_hot_encode(seq, max_length):\n",
    "    mapping = {'A': 0, 'T': 1, 'G': 2, 'C': 3, 'N': 4}  # 碱基映射\n",
    "    one_hot = np.zeros((max_length, len(mapping)), dtype=np.float32)\n",
    "    for i, char in enumerate(seq[:max_length]):  # 限制最大长度\n",
    "        if char in mapping:\n",
    "            one_hot[i, mapping[char]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the length of each sequence （计算每条序列的长度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取所有序列的最大长度\n",
    "max_length = max(len(seq) for seq in all_sequences)\n",
    "\n",
    "# 转换所有序列为 One-hot 编码\n",
    "encoded_sequences = np.array([one_hot_encode(seq, max_length) for seq in all_sequences])\n",
    "encoded_labels = np.array(all_labels, dtype=np.int32)\n",
    "\n",
    "# 打印编码结果\n",
    "print(f\"One-hot Coding is complete! Total number of samples:{encoded_sequences.shape[0]}\")  # 样本数 编码完成！总样本数：20\n",
    "print(f\"The encoding shape of each sequence is:{encoded_sequences.shape[1:]}\")  # 例如 (max_length, 5) 每条序列的编码形状：(894, 5)\n",
    "print(f\"Label shape:{encoded_labels.shape}\")  # 标签形状：(20,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据集\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    encoded_sequences, encoded_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 打印数据划分结果\n",
    "print(f\"Number of training set samples:{train_data.shape[0]}\")  #训练集样本数：16\n",
    "print(f\"Number of test set samples:{test_data.shape[0]}\")       #测试集样本数：4\n",
    "print(f\"The shape of each sequence is:{train_data.shape[1:]}\")        #每条序列的形状：(894, 5)\n",
    "print(f\"Label shape: Training set:{train_labels.shape}, test set:{test_labels.shape}\")       #标签形状：训练集：(16,)，测试集：(4,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "\n",
    "# Submit sequence\n",
    "# 送检序列\n",
    "query_sequence = Seq(\"\"\"\n",
    "CTCCACTCGTCTGCTGCTCGGTGGACTGGCCCAGAAATCTGTACTTGATACTCTGCGGGAAGAAGGTGAGGACGTTGAACTCGACGATATCAGAAAAGCAGCTTACGGAGGAACCTGGGCAGTTGAATCAGGTGGCCCGGAGCCGGGTGTTGGCTGTGCAGGCCGAGGTATCATAACCGCGATTAACATGCTTGAATCCCTTGGCGCCTATGAGGAGAGCGAAAGCCTTGACTACGCCTTCTATGATGTTCTCGGTGATGTTGTTTGCGGTGGTTTTGCCATGCCCATCAGAGATGGTAAGGCGGAAGAAATCTATATCGTTGTCTCA\n",
    "\"\"\".strip())\n",
    "\n",
    "# Minimum match length\n",
    "# 最小匹配长度\n",
    "min_length = 11\n",
    "\n",
    "def find_and_count_repeats(query_sequence, reference_sequences, min_length=5):\n",
    "    \"\"\"\n",
    "    统计送检序列与参考序列之间的匹配片段数量，并返回匹配片段\n",
    "    :param query_sequence: 送检序列\n",
    "    :param reference_sequences: 参考序列列表\n",
    "    :param min_length: 每次截取的长度（默认为 5）\n",
    "    :return: 每个参考序列匹配片段的数量和匹配的片段列表\n",
    "    \"\"\"\n",
    "    # 结果存储每个样本的匹配数量和匹配片段\n",
    "    # The result stores the number of matches and matching fragments for each sample\n",
    "    match_details = []\n",
    "\n",
    "    # Iterate through each reference sequence\n",
    "    # 遍历每个参考序列\n",
    "    for ref_idx, reference_sequence in enumerate(reference_sequences):\n",
    "        match_count = 0\n",
    "        matched_fragments = set()  # 使用集合避免重复记录相同片段\n",
    "\n",
    "        # Traverse the inspection sequence and use a sliding window with a step size of 1 to intercept segments of min_length length\n",
    "        # 遍历送检序列，以步长为 1 滑动窗口截取 min_length 长度的片段\n",
    "        for i in range(len(query_sequence) - min_length + 1):\n",
    "            query_fragment = str(query_sequence[i:i + min_length])  # 将片段转换为字符串\n",
    "            \n",
    "            # If the fragment is in the reference sequence, record a match\n",
    "            # 如果片段在参考序列中，记录匹配\n",
    "            if query_fragment in reference_sequence:\n",
    "                match_count += 1\n",
    "                matched_fragments.add(query_fragment)\n",
    "\n",
    "        # Save the number of matches and the matching fragment\n",
    "        # 保存匹配数量和匹配片段\n",
    "        match_details.append((match_count, list(matched_fragments)))\n",
    "\n",
    "    return match_details\n",
    "\n",
    "# Call function to count matches and fragments\n",
    "# 调用函数计算匹配数量和片段\n",
    "results = find_and_count_repeats(query_sequence, all_sequences, min_length=min_length)\n",
    "\n",
    "# 打印结果\n",
    "for idx, (count, fragments) in enumerate(results):\n",
    "    print(f\"sample {idx} The number of long continuous matching fragments with the submitted sequence:{count}\")        #样本 0 与送检序列的长连续匹配片段数量：3\n",
    "    if fragments:\n",
    "        print(f\"Matching fragments:{', '.join(fragments)}\")      #匹配片段：GTTGTTGCGGT, GGTGGTTTTGC, GGTGGTTTTGC\n",
    "    else:\n",
    "        print(\"No matching fragments.\")     #没有匹配片段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the characteristic of the function\n",
    "# 计算特征函数\n",
    "def calculate_features(sequence):\n",
    "    # ATCG share\n",
    "    # ATCG 所占比例\n",
    "    length = len(sequence)\n",
    "    A_ratio = sequence.count('A') / length\n",
    "    T_ratio = sequence.count('T') / length\n",
    "    C_ratio = sequence.count('C') / length\n",
    "    G_ratio = sequence.count('G') / length\n",
    "    # GC content\n",
    "    # GC含量\n",
    "    gc_content = (sequence.count('G') + sequence.count('C')) / length\n",
    "\n",
    "    # 大于 4 个碱基长度的连续重复序列数\n",
    "    long_repeats_count = sum(1 for i in range(len(sequence) - 4) if sequence[i:i + 5] == sequence[i] * 5)\n",
    "    # Sequence entropy (Shannon entropy)\n",
    "    # 序列熵（香农熵）\n",
    "    base_counts = [sequence.count(base) / length for base in \"ATCG\"]\n",
    "    seq_entropy = entropy(base_counts)\n",
    "    # Maximum base repeat length\n",
    "    # 最长碱基重复长度\n",
    "    max_repeat_length = max(len(list(g)) for _, g in groupby(sequence))\n",
    "\n",
    "    return {\n",
    "        \"A_Ratio\": A_ratio,\n",
    "        \"T_Ratio\": T_ratio,\n",
    "        \"C_Ratio\": C_ratio,\n",
    "        \"G_Ratio\": G_ratio,\n",
    "        \"GC_Content\": gc_content,\n",
    "        \"Long_Repeats_Count\": long_repeats_count,\n",
    "        \"Sequence_Entropy\": seq_entropy,\n",
    "        \"Max_Repeat_Length\": max_repeat_length\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gc_content(sequence):\n",
    "    \"\"\"手动计算GC含量比例\"\"\"\n",
    "    counts = Counter(sequence)\n",
    "    g, c = counts['G'], counts['C']\n",
    "    return ((g + c) / sum(counts.values())) * 100\n",
    "\n",
    "def calculate_at_bias(sequence):\n",
    "    \"\"\"计算A/T偏向值\"\"\"\n",
    "    counts = Counter(sequence)\n",
    "    a, t = counts['A'], counts['T']\n",
    "    return abs(a - t) / sum(counts.values())\n",
    "\n",
    "def count_continuous_repeats(sequence):\n",
    "    \"\"\"计算 A/T/C/G 连续重复 3 次及以上的比例，返回每种碱基的比例和最大连续重复次数\"\"\"\n",
    "    repeat_counts = {\"A\": 0, \"T\": 0, \"C\": 0, \"G\": 0}\n",
    "    max_repeats = {\"A\": 0, \"T\": 0, \"C\": 0, \"G\": 0}\n",
    "    total_length = len(sequence)\n",
    "    \n",
    "    for base in repeat_counts.keys():\n",
    "        # 创建滑动窗口统计重复次数\n",
    "        count = 0\n",
    "        max_count = 0\n",
    "        \n",
    "        for char in sequence:\n",
    "            if char == base:\n",
    "                count += 1\n",
    "                max_count = max(max_count, count)  # 更新最大连续重复次数\n",
    "            else:\n",
    "                count = 0\n",
    "        \n",
    "        repeat_counts[base] = sum(1 for i in range(len(sequence) - 2) if sequence[i:i + 3] == base * 3)\n",
    "        max_repeats[base] = max_count  # 保存最大重复次数\n",
    "\n",
    "    repeat_ratios = {base: repeat_counts[base] / total_length for base in repeat_counts.keys()}\n",
    "\n",
    "    return repeat_ratios, max_repeats\n",
    "\n",
    "\n",
    "def calculate_entropy(sequence):\n",
    "    \"\"\"计算香农熵\"\"\"\n",
    "    counts = Counter(sequence)\n",
    "    total = sum(counts.values())\n",
    "    probabilities = [count / total for count in counts.values()]\n",
    "    return -sum(p * math.log2(p) for p in probabilities)\n",
    "\n",
    "# 创建数据表存储结果\n",
    "results = []\n",
    "\n",
    "\n",
    "for idx, seq in enumerate(all_sequences):\n",
    "    gc_content = calculate_gc_content(seq)\n",
    "    at_bias = calculate_at_bias(seq)\n",
    "    \n",
    "    # 获取重复比例和最大重复次数\n",
    "    repeat_ratios, max_repeats = count_continuous_repeats(seq)  \n",
    "    \n",
    "    entropy = calculate_entropy(seq)\n",
    "\n",
    "    results.append({\n",
    "        \"Sample\": idx + 1,\n",
    "        \"GC Content (%)\": gc_content,\n",
    "        \"A/T Bias\": at_bias,\n",
    "        \"A Repeat Ratio\": repeat_ratios[\"A\"],  # 添加 A 重复比例\n",
    "        \"T Repeat Ratio\": repeat_ratios[\"T\"],  # 添加 T 重复比例\n",
    "        \"C Repeat Ratio\": repeat_ratios[\"C\"],  # 添加 C 重复比例\n",
    "        \"G Repeat Ratio\": repeat_ratios[\"G\"],  # 添加 G 重复比例\n",
    "        \"Max A Repeat\": max_repeats[\"A\"],  # 添加 A 最大重复次数\n",
    "        \"Max T Repeat\": max_repeats[\"T\"],  # 添加 T 最大重复次数\n",
    "        \"Max C Repeat\": max_repeats[\"C\"],  # 添加 C 最大重复次数\n",
    "        \"Max G Repeat\": max_repeats[\"G\"],  # 添加 G 最大重复次数\n",
    "        \"Entropy\": entropy\n",
    "    })\n",
    "# GC 含量\n",
    "# A/T 偏向值\n",
    "# A/T/C/G 的重复比例\n",
    "# A/T/C/G 的最大连续重复次数\n",
    "# 香农熵\n",
    "\n",
    "\n",
    "\n",
    "# 转换为数据框\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 展示数据表\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation analysis\n",
    "# 选择数值型列进行相关性分析\n",
    "numeric_data = df.select_dtypes(include=[np.number])\n",
    "# Calculate the correlation matrix\n",
    "# 计算相关性矩阵\n",
    "correlation_matrix = numeric_data.corr()\n",
    "# Plotting a correlation matrix heatmap\n",
    "# 绘制相关性矩阵热图\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix for Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征和目标\n",
    "X = df.drop(columns=['Sample'])  # 去掉样本编号列\n",
    "y = pd.cut(df['GC Content (%)'], bins=3, labels=[\"Low\", \"Medium\", \"High\"])  # 通过GC含量分成3类\n",
    "\n",
    "# 检查新目标变量的类别分布\n",
    "print(y.value_counts())\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define pipeline with scaling and RandomForest\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('rf', RandomForestClassifier(random_state=42))  \n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for RandomForest\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [5, 10, 20, None],\n",
    "    'rf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "rf_grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = rf_grid.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# 输出分类报告Output classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "ConfusionMatrixDisplay.from_estimator(rf_grid, X_test, y_test, cmap='Blues')\n",
    "plt.title('Confusion Matrix (RandomForest)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 特征和目标\n",
    "X = df.drop(columns=['Sample'])\n",
    "y = df['Sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Lasso Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a pipeline: scaling + Lasso Regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('lasso', Lasso(max_iter=10000))  \n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid for alpha\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV for hyperparameter tuning\n",
    "lasso_grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = lasso_grid.best_params_['lasso__alpha']\n",
    "print(f\"Best Alpha (Regularization Strength): {best_alpha}\")\n",
    "\n",
    "# Predict on the test set using the best Lasso model\n",
    "y_pred = lasso_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse_lasso = np.sqrt(mse)\n",
    "r2_lasso = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso:.4f}\")\n",
    "print(f\"R² Score: {r2_lasso:.4f}\")\n",
    "\n",
    "# Scatter plot: Actual vs Predicted for Lasso Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='b', label=\"Predicted vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "plt.title('Actual vs Predicted (Lasso Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Actual vs Predicted values \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", alpha=0.7, linewidth=1.5)\n",
    "plt.plot(range(len(y_pred)), y_pred, label=\"Predicted\", color=\"blue\", alpha=0.7, linewidth=1.5)\n",
    "plt.title(\"Testing Data: Actual vs Predicted Values (Lasso Regression)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Target Variable\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# test size 0.2：就是剩余80%训练，20参加测试\n",
    "\n",
    "# 模型初始化\n",
    "ridge = Ridge(alpha=500)  # 使用 alpha=500\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# 计算 RMSE 和 R^2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "\n",
    "# 绘制实际值与预测值的散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='b', label='Predicted')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal Fit')\n",
    "plt.title('Actual vs Predicted (Ridge Regression)')\n",
    "plt.xlabel('Actual Sample')\n",
    "plt.ylabel('Predicted Sample')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 折线图：实际值与预测值\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(len(y_test)), y_test, label='Actual', color='red', marker='o')\n",
    "plt.plot(range(len(y_pred)), y_pred, label='Predicted', color='blue', marker='x')\n",
    "plt.title('Testing Data: Actual vs Predicted Samples')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sample')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Randon Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# 特征和目标\n",
    "X = df.drop(columns=['Sample'])\n",
    "y = df['Sample']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# 创建带有缩放和随机森林的管道\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('model', RandomForestRegressor(random_state=42))  \n",
    "])\n",
    "\n",
    "# 使用 GridSearchCV 进行超参数调优\n",
    "rf_grid_search = GridSearchCV(\n",
    "    rf_pipeline, \n",
    "    param_grid=param_grid_rf, \n",
    "    cv=3,  \n",
    "    scoring='neg_mean_squared_error',  \n",
    "    verbose=1,  \n",
    "    n_jobs=1  \n",
    ")\n",
    "\n",
    "# 在训练数据上拟合 GridSearchCV\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 提取最佳模型\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# 计算评估指标\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Best Parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Random Forest Regressor (GridSearchCV) - RMSE: {rmse_rf:.4f}, R^2 Score: {r2_rf:.4f}\")\n",
    "\n",
    "# 绘制实际值与预测值的散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.7, color='b', label='Predicted')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal Fit')\n",
    "plt.title('Actual vs Predicted (Random Forest Regression)')\n",
    "plt.xlabel('Actual Sample')\n",
    "plt.ylabel('Predicted Sample')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 折线图：实际值与预测值\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(len(y_test)), y_test, label='Actual', color='red', marker='o')\n",
    "plt.plot(range(len(y_pred_rf)), y_pred_rf, label='Predicted', color='blue', marker='x')\n",
    "plt.title('Testing Data: Actual vs Predicted Samples (Random Forest Regression)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sample')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我很想知道这是什么参数会更加重要，所以我引入了：GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Random Forest Regressor (GridSearchCV) - RMSE: {rmse_rf:.4f}, R² Score: {r2_rf:.4f}\")\n",
    "\n",
    "# Scatter Plot: Actual vs Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.7, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "plt.title(f'Actual vs Predicted (Random Forest Regressor)\\nRMSE: {rmse_rf:.4f}, R²: {r2_rf:.4f}')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Extract feature importances and sort them\n",
    "feature_importances = best_rf_model.named_steps['model'].feature_importances_\n",
    "feature_names = X_train.columns if isinstance(X_train, pd.DataFrame) else [f\"Feature {i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Limit to Top-N features\n",
    "top_n = min(len(importance_df), 20)  # Top-N features (default 20, but limited by total features)\n",
    "top_features = importance_df.head(top_n)\n",
    "\n",
    "# Line Plot: Actual vs Predicted Values for Random Forest\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", alpha=0.7, linewidth=1.5, marker='o')\n",
    "plt.plot(range(len(y_pred_rf)), y_pred_rf, label=\"Predicted\", color=\"blue\", alpha=0.7, linewidth=1.5, marker='x')\n",
    "plt.title(\"Testing Data: Actual vs Predicted Values (Random Forest)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Sample Values\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Bar Plot: Feature Importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color=\"skyblue\")\n",
    "plt.title('Top Feature Importances (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.gca().invert_yaxis()  # Reverse the order for better visualization\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Gradient Boosting Model (GBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 将 numpy 数组转换为 DataFrame（如果需要）\n",
    "# X_train = pd.DataFrame(X_train, columns=X.columns if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X.shape[1])])\n",
    "# X_test = pd.DataFrame(X_test, columns=X.columns if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X.shape[1])])\n",
    "\n",
    "# # 转换布尔类型为整数\n",
    "# X_train = X_train.astype({col: 'int' for col in X_train.select_dtypes(include=['bool']).columns})\n",
    "# X_test = X_test.astype({col: 'int' for col in X_test.select_dtypes(include=['bool']).columns})\n",
    "\n",
    "# # 使用均值插补缺失值\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# X_train = imputer.fit_transform(X_train)\n",
    "# X_test = imputer.transform(X_test)\n",
    "\n",
    "# # 确保目标变量的形状是一维\n",
    "# y_train = y_train.ravel()\n",
    "\n",
    "# # 定义参数网格\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200,],\n",
    "#     'learning_rate': [ 0.05, 0.1],\n",
    "#     'max_depth': [3, 4]\n",
    "# }\n",
    "\n",
    "\n",
    "# # 初始化 LightGBM 模型\n",
    "# lgbm = LGBMRegressor(random_state=42, device='cpu', verbose=-1)  # 设置详细日志\n",
    "\n",
    "# # 使用 GridSearchCV 进行超参数调优\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=lgbm,               # 模型\n",
    "#     param_grid=param_grid,        # 参数网格\n",
    "#     cv=3,                         # 交叉验证折数\n",
    "#     scoring='neg_mean_squared_error',  # 评估指标\n",
    "#     verbose=1,                    # 输出详细信息\n",
    "#     n_jobs=1                     # 并行计算\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 获取最佳模型和参数\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# # 在测试集上进行预测并评估模型\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse_gbm = np.sqrt(mse)\n",
    "# r2_gbm = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Tuned LightGBM - RMSE: {rmse_gbm:.4f}, R²: {r2_gbm:.4f}\")\n",
    "\n",
    "# # 可视化实际值与预测值的散点图\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.7, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "# plt.title(f'Actual vs Predicted (LightGBM Regressor)\\nRMSE: {rmse_gbm:.4f}, R²: {r2_gbm:.4f}')\n",
    "# plt.xlabel('Actual Values')\n",
    "# plt.ylabel('Predicted Values')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# # 折线图：实际值与预测值\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", marker='o', alpha=0.7, linewidth=1.5)\n",
    "# plt.plot(range(len(y_pred)), y_pred, label=\"Predicted\", color=\"blue\", marker='x', alpha=0.7, linewidth=1.5)\n",
    "# plt.title(\"Testing Data: Actual vs Predicted Values (LightGBM)\")\n",
    "# plt.xlabel(\"Index\")\n",
    "# plt.ylabel(\"Sample Values\")\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# # 提取特征重要性\n",
    "# feature_importances = best_model.feature_importances_\n",
    "# feature_names = X.columns if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# # 可视化特征重要性\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'Feature': feature_names,\n",
    "#     'Importance': feature_importances\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Bar Plot: Feature Importances\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.barh(importance_df['Feature'], importance_df['Importance'], color=\"skyblue\")\n",
    "# plt.title('Feature Importances (LightGBM)')\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 预处理：标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA 降维\n",
    "pca = PCA(n_components=0.95)  # 保留95%的方差\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# 定义 SVM 超参数搜索范围\n",
    "svm_param_dist = {\n",
    "    'kernel': ['linear', 'poly', 'rbf'],  # 核函数类型\n",
    "    'C': np.logspace(-1, 2, 10),         # 正则化参数\n",
    "    'epsilon': [0.1, 0.2, 0.5]           # 回归松弛范围\n",
    "}\n",
    "\n",
    "# 随机搜索调参\n",
    "svm_random = RandomizedSearchCV(\n",
    "    SVR(), \n",
    "    param_distributions=svm_param_dist, \n",
    "    n_iter=10,                          # 搜索次数\n",
    "    cv=3,                               # 交叉验证\n",
    "    scoring='neg_mean_squared_error',   # 评分方式\n",
    "    random_state=42, \n",
    "    n_jobs=-1                           # 并行计算\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "print(\"开始训练 SVM 模型...\")\n",
    "svm_random.fit(X_train_pca, y_train)\n",
    "print(\"SVM 模型训练完成！\")\n",
    "\n",
    "# 最佳参数\n",
    "best_svm_params = svm_random.best_params_\n",
    "print(f\"Best SVM Parameters: {best_svm_params}\")\n",
    "\n",
    "# 在测试集上预测\n",
    "y_pred_svm = svm_random.best_estimator_.predict(X_test_pca)\n",
    "\n",
    "# 计算评估指标\n",
    "rmse_svm = mean_squared_error(y_test, y_pred_svm, squared=False)\n",
    "r2_svm = r2_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM RMSE: {rmse_svm:.4f}\")\n",
    "print(f\"SVM R²: {r2_svm:.4f}\")\n",
    "\n",
    "# 可视化实际值与预测值的散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_svm, alpha=0.7, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "plt.title('Actual vs Predicted (SVM)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 折线图：实际值与预测值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", alpha=0.7, linewidth=1.5)\n",
    "plt.plot(range(len(y_pred_svm)), y_pred_svm, label=\"Predicted\", color=\"blue\", alpha=0.7, linewidth=1.5)\n",
    "plt.title(\"Testing Data: Actual vs Predicted Values (SVM)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Target Variable\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 KNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 定义 KNN 参数网格\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10],            # 邻居数\n",
    "    'weights': ['uniform', 'distance'],      # 权重方式\n",
    "    'metric': ['euclidean', 'manhattan']     # 距离度量\n",
    "}\n",
    "\n",
    "# 使用 GridSearchCV 进行超参数调优\n",
    "knn_grid = GridSearchCV(\n",
    "    KNeighborsRegressor(), \n",
    "    param_grid=knn_param_grid, \n",
    "    cv=5,                                     # 5 折交叉验证\n",
    "    scoring='neg_mean_squared_error',         # 评分指标\n",
    "    n_jobs=-1                                 # 并行计算\n",
    ")\n",
    "\n",
    "print(\"开始训练 KNN 模型...\")\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "print(\"KNN 模型训练完成！\")\n",
    "\n",
    "# 最佳参数\n",
    "best_knn_params = knn_grid.best_params_\n",
    "print(f\"Best KNN Parameters: {best_knn_params}\")\n",
    "\n",
    "# 在测试集上预测\n",
    "y_pred_knn = knn_grid.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# 计算评估指标\n",
    "rmse_knn = mean_squared_error(y_test, y_pred_knn, squared=False)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"KNN RMSE: {rmse_knn:.4f}\")\n",
    "print(f\"KNN R²: {r2_knn:.4f}\")\n",
    "\n",
    "# 可视化实际值与预测值的散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_knn, alpha=0.7, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "plt.title(f'Actual vs Predicted (KNN Regressor)\\nRMSE: {rmse_knn:.4f}, R²: {r2_knn:.4f}')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 折线图：实际值与预测值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", alpha=0.7, linewidth=1.5)\n",
    "plt.plot(range(len(y_pred_knn)), y_pred_knn, label=\"Predicted (KNN)\", color=\"blue\", alpha=0.7, linewidth=1.5)\n",
    "plt.title(\"Testing Data: Actual vs Predicted Values (KNN)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Target Variable\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 输出最佳参数、RMSE 和 R² 值\n",
    "print(f\"Final Results:\\nBest Parameters: {best_knn_params}\\nRMSE: {rmse_knn:.4f}\\nR²: {r2_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a pipeline: scaling + Lasso Regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('lasso', Lasso(max_iter=10000))  \n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid for alpha\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV for hyperparameter tuning\n",
    "lasso_grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = lasso_grid.best_params_['lasso__alpha']\n",
    "print(f\"Best Alpha (Regularization Strength): {best_alpha}\")\n",
    "\n",
    "# Predict on the test set using the best Lasso model\n",
    "y_pred = lasso_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse_lasso = np.sqrt(mse)\n",
    "r2_lasso = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso:.4f}\")\n",
    "print(f\"R² Score: {r2_lasso:.4f}\")\n",
    "\n",
    "# Scatter plot: Actual vs Predicted for Lasso Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='b', label=\"Predicted vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "plt.title('Actual vs Predicted (Lasso Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Actual vs Predicted values \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", alpha=0.7, linewidth=1.5)\n",
    "plt.plot(range(len(y_pred)), y_pred, label=\"Predicted\", color=\"blue\", alpha=0.7, linewidth=1.5)\n",
    "plt.title(\"Testing Data: Actual vs Predicted Values (Lasso Regression)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Target Variable\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义神经网络的参数网格\n",
    "nn_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],  # 隐藏层结构\n",
    "    'activation': ['relu', 'tanh'],                   # 激活函数\n",
    "    'solver': ['adam', 'sgd'],                        # 优化器\n",
    "    'alpha': [0.0001, 0.001, 0.01]                    # L2正则化系数\n",
    "}\n",
    "\n",
    "# 使用 GridSearchCV 对神经网络进行超参数调优\n",
    "print(\"开始训练神经网络模型...\")\n",
    "nn_grid = GridSearchCV(\n",
    "    MLPRegressor(max_iter=500, random_state=42),  # 最大迭代次数设置为 500\n",
    "    param_grid=nn_param_grid, \n",
    "    cv=5,                                        # 5 折交叉验证\n",
    "    scoring='neg_mean_squared_error',            # 使用负均方误差作为评分标准\n",
    "    n_jobs=-1                                    # 并行计算\n",
    ")\n",
    "nn_grid.fit(X_train_scaled, y_train)\n",
    "print(\"神经网络模型训练完成！\")\n",
    "\n",
    "# 最佳参数\n",
    "best_nn_params = nn_grid.best_params_\n",
    "print(f\"Best Neural Network Parameters: {best_nn_params}\")\n",
    "\n",
    "# 使用最佳模型预测测试集\n",
    "y_pred_nn = nn_grid.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# 计算评估指标\n",
    "rmse_nn = mean_squared_error(y_test, y_pred_nn, squared=False)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "print(f\"Neural Network RMSE: {rmse_nn:.4f}\")\n",
    "print(f\"Neural Network R²: {r2_nn:.4f}\")\n",
    "\n",
    "# 可视化实际值与预测值的散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_nn, alpha=0.7, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit (y=x)\")\n",
    "plt.title(f'Actual vs Predicted (Neural Network)\\nRMSE: {rmse_nn:.4f}, R²: {r2_nn:.4f}')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 折线图：实际值与预测值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual\", color=\"red\", alpha=0.7, linewidth=1.5)\n",
    "plt.plot(range(len(y_pred_nn)), y_pred_nn, label=\"Predicted (Neural Network)\", color=\"blue\", alpha=0.7, linewidth=1.5)\n",
    "plt.title(\"Testing Data: Actual vs Predicted Values (Neural Network)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Target Variable\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 定义特征名（替换为您提取的特征名）\n",
    "input_features = [\n",
    "    \"GC Content (%)\", \n",
    "    \"A/T Bias\", \n",
    "    \"A Repeat Ratio\", \n",
    "    \"T Repeat Ratio\", \n",
    "    \"C Repeat Ratio\", \n",
    "    \"G Repeat Ratio\", \n",
    "    \"Max A Repeat\", \n",
    "    \"Max T Repeat\", \n",
    "    \"Max C Repeat\", \n",
    "    \"Max G Repeat\"\n",
    "]\n",
    "\n",
    "# 模拟权重矩阵（请替换为真实权重）\n",
    "n_input = len(input_features)\n",
    "n_hidden1 = 5  # 第一隐藏层神经元个数\n",
    "n_hidden2 = 3  # 第二隐藏层神经元个数\n",
    "n_output = 1   # 输出层神经元个数\n",
    "\n",
    "input_to_hidden1_weights = np.random.randn(n_input, n_hidden1)  \n",
    "hidden1_to_hidden2_weights = np.random.randn(n_hidden1, n_hidden2)  \n",
    "hidden2_to_output_weights = np.random.randn(n_hidden2, n_output) \n",
    "\n",
    "weights = [input_to_hidden1_weights, hidden1_to_hidden2_weights, hidden2_to_output_weights]\n",
    "\n",
    "# 神经网络层设置\n",
    "layers = [\n",
    "    {'neurons': n_input, 'label': 'Input Layer'},\n",
    "    {'neurons': n_hidden1, 'label': 'Hidden Layer 1'},\n",
    "    {'neurons': n_hidden2, 'label': 'Hidden Layer 2'},\n",
    "    {'neurons': n_output, 'label': 'Output Layer'}\n",
    "]\n",
    "\n",
    "# 创建神经网络图\n",
    "G = nx.DiGraph()\n",
    "positions = {}\n",
    "y_offset = 2\n",
    "x_offset = 3\n",
    "node_labels = {}\n",
    "edge_labels = {}\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    for j in range(layer['neurons']):\n",
    "        node_name = f'{layer[\"label\"]}_{j+1}'\n",
    "        G.add_node(node_name, layer=layer['label'])\n",
    "        positions[node_name] = (i * x_offset, j * y_offset)\n",
    "        node_labels[node_name] = layer['label'] if i == 0 or i == len(layers) - 1 else ''\n",
    "\n",
    "        # 连接前一层的神经元\n",
    "        if i > 0:\n",
    "            prev_layer = layers[i - 1]\n",
    "            for k in range(prev_layer['neurons']):\n",
    "                prev_node_name = f'{prev_layer[\"label\"]}_{k+1}'\n",
    "                G.add_edge(prev_node_name, node_name)\n",
    "\n",
    "                # 添加权重并检查索引是否越界\n",
    "                if i - 1 < len(weights) and k < weights[i - 1].shape[0] and j < weights[i - 1].shape[1]:\n",
    "                    edge_weight = weights[i - 1][k, j]\n",
    "                else:\n",
    "                    edge_weight = 0  # 如果索引超出范围，设置为0\n",
    "                edge_labels[(prev_node_name, node_name)] = f'{edge_weight:.2f}'\n",
    "\n",
    "# 绘制神经网络\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw_networkx_nodes(G, positions, node_size=600, node_color='skyblue', alpha=0.9)\n",
    "nx.draw_networkx_edges(G, positions, arrows=False, alpha=0.3)\n",
    "nx.draw_networkx_labels(G, positions, labels=node_labels, font_size=10)\n",
    "\n",
    "# 添加层标签\n",
    "for i, layer in enumerate(layers):\n",
    "    x_position = i * x_offset\n",
    "    y_position = (layer['neurons'] - 1) * y_offset / 2\n",
    "    plt.text(x_position, y_position + 2, layer['label'], fontsize=12, ha='center', fontweight='bold')\n",
    "\n",
    "# 添加特征名和输出标签\n",
    "for i, feature in enumerate(input_features):\n",
    "    plt.text(-1, i * y_offset, feature, fontsize=10, ha='right')\n",
    "plt.text(len(layers) * x_offset - 1, y_offset / 2, \"Predicted Value\", fontsize=10, ha='left')\n",
    "\n",
    "# 绘制边权重\n",
    "nx.draw_networkx_edge_labels(G, positions, edge_labels=edge_labels, font_size=8, label_pos=0.5)\n",
    "\n",
    "plt.title('Neural Network Architecture', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_lasso, rmse_rf, rmse_svm, rmse_knn, rmse_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总模型结果\n",
    "model_results = {\n",
    "    'Model': ['Lasso Regression', 'Random Forest', 'SVM', 'KNN', 'Neural Network'],\n",
    "    'RMSE': [rmse_lasso, rmse_rf, rmse_svm, rmse_knn, rmse_nn],\n",
    "    'R²': [r2_lasso, r2_rf, r2_svm, r2_knn, r2_nn]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "# 打印结果表格\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# 可视化 RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='RMSE', data=results_df, palette='Blues_d')\n",
    "plt.title('Model Comparison: RMSE', fontsize=14)\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 可视化 R²\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='R²', data=results_df, palette='Greens_d')\n",
    "plt.title('Model Comparison: R²', fontsize=14)\n",
    "plt.ylabel('R² Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
